
regression task: predict the location(x, y) of the object.
classification task: predict the class of the object.

Two-stage network:
1.Region proposal network(RPN)
2.Classifier

One-stage network:
YOLO
SSD

Feature Engineering:
Standard, such as: resizing, normalization
data augmentation

Precision
Precision = Correct detections / Total detections

NMS: remove duplicate bounding boxes.
# https://zhuanlan.zhihu.com/p/511151467
Non-Maximum Suppression

ask doubao to give an example, then you can understand it.

DETR: detection transformer
Transformer object detection.
https://blog.csdn.net/m0_48086806/article/details/132155312

How Transformer-based object detection architectures differ from one-stage or twostage models, and what are their
pros and cons
Example Scenario: Detecting Vehicles in a Traffic Scene
1. One - stage Model (YOLO - You Only Look Once)
Feature extraction and detection process
Feature extraction: YOLO uses a CNN backbone, such as Darknet, to extract features from the input traffic image. For example, in YOLOv5, the input traffic image is passed through a series of convolutional layers that gradually reduce the spatial dimensions and increase the number of channels. These convolutional layers are designed to capture local features like the shape of vehicle parts (wheels, headlights).
Detection process: In a single forward pass through the network, YOLO divides the image into a grid of cells. Each cell is responsible for predicting bounding boxes and class labels for objects whose centers fall within that cell. For instance, if a car's center is in a particular grid cell, that cell will predict the bounding box coordinates (x, y, width, height) and the class label “car”.
Pros
High speed: Suppose you are developing a real - time traffic monitoring system. YOLO can process traffic images at a very high frame rate, say 30 - 60 frames per second. This allows you to quickly detect vehicles in a continuous stream of traffic footage, which is crucial for applications like traffic flow analysis or real - time accident detection.
Simplicity: The architecture of YOLO is relatively straightforward. You can easily implement it in your project with the help of open - source libraries like PyTorch or TensorFlow. For a developer new to object detection, it's easier to understand and modify the YOLO code compared to more complex architectures.
Cons
Lower accuracy: In a crowded traffic scene with many small vehicles (like motorcycles), YOLO may miss some detections or misclassify them. For example, if a motorcycle is partially occluded by a larger truck, YOLO might fail to accurately detect it due to its limited ability to capture fine - grained details and context.
Sensitivity to anchor design: The performance of YOLO depends on the pre - defined anchor boxes. If the anchor boxes are not well - tuned for the specific traffic dataset (e.g., if the aspect ratios of the anchor boxes do not match the actual aspect ratios of vehicles in the traffic scene), the detection accuracy can be significantly affected.
2. Two - stage Model (Faster R - CNN)
Feature extraction and detection process
Feature extraction: Similar to YOLO, Faster R - CNN uses a CNN backbone (e.g., ResNet) to extract features from the traffic image. The convolutional layers in the backbone extract hierarchical features, from low - level edges to high - level object - like features.
Detection process: In the first stage, a region proposal network (RPN) generates a set of region proposals from the feature maps. For example, in a traffic image, the RPN might propose regions that are likely to contain vehicles. In the second stage, these proposals are further refined and classified. Each proposal is cropped from the feature maps, passed through a fully - connected layer, and then classified as a specific vehicle class (car, bus, etc.) and its bounding box is refined.
Pros
High accuracy: In a complex traffic scenario where vehicles are of different sizes and orientations, Faster R - CNN can achieve higher accuracy compared to YOLO. For example, it can better detect small motorcycles in a multi - lane traffic scene and accurately classify different types of large vehicles like trucks and buses.
Robustness: Faster R - CNN is more robust to object occlusion. If a car is partially blocked by another vehicle, the region proposal step can still identify the potential location of the occluded car, and the second - stage refinement can improve the detection accuracy.
Cons
Slow speed: Due to its two - stage process, Faster R - CNN is much slower than YOLO. In a real - time traffic monitoring system, it may only be able to process 5 - 10 frames per second, which is not sufficient for applications that require immediate responses.
Complexity: The architecture of Faster R - CNN is more complex than YOLO. It involves multiple components (RPN, classification, and refinement networks), which makes it more difficult to train and deploy. Tuning the hyperparameters of Faster R - CNN also requires more expertise and computational resources.
3. Transformer - based Model (DETR - Detection Transformer)
Feature extraction and detection process
Feature extraction: DETR first uses a CNN backbone to extract initial features from the traffic image. Then, these features are flattened and passed through a Transformer encoder - decoder architecture. The self - attention mechanism in the Transformer allows the model to capture global relationships between different parts of the image. For example, it can understand the relative positions of vehicles in different lanes and their interactions.
Detection process: DETR treats object detection as a set prediction problem. It directly predicts a fixed set of object queries, each representing an object in the image. For a traffic image, these queries will predict the bounding boxes and class labels of all the vehicles in the scene without the need for anchor boxes or region proposals.
Pros
Global context modeling: In a traffic scene where there are traffic signs and multiple vehicles interacting, DETR can better understand the context. For example, it can use the information from a traffic sign to better classify and locate the vehicles in the scene. If a “no - left - turn” sign is detected, it can help in more accurately predicting the movement and position of vehicles approaching the intersection.
End - to - end training: DETR can be trained end - to - end, which simplifies the training process. You don't need to train separate components for region proposal and classification like in Faster R - CNN. This makes it easier to optimize the model for the traffic detection task.
No need for anchors: Since DETR doesn't rely on pre - defined anchor boxes, it can be more flexible in detecting vehicles of different sizes and aspect ratios in the traffic scene. It can adapt better to new types of vehicles or unusual vehicle orientations.
Cons
Computational complexity: Training and inferencing DETR on a large - scale traffic dataset can be very computationally expensive. It requires a powerful GPU and a long training time. For a small - scale traffic monitoring project with limited computational resources, it may not be a practical choice.
Data requirements: DETR needs a large amount of labeled traffic data to perform well. If you have a small dataset of traffic images, the model may overfit and not generalize well to new traffic scenes.
Lack of interpretability: It can be difficult to understand how the self - attention mechanism in DETR arrives at its predictions. For example, it's not clear which parts of the traffic image the model is focusing on to detect a particular vehicle, which can be a problem in applications where interpretability is important.


Distributed training techniques to improve object detection on a larger dataset
(1)Data Parallelism
    Synchronous Update
    Asynchronous Update
(2)Model Parallelism
(3)Hybrid Parallelism

Evaluate bias in face detection systems
1. Data - related Bias
Representation in Training Data
Demographic Groups: Check if the training data adequately represents different demographic groups in terms of race, gender, age, and ethnicity. For example, if a face detection system is trained mainly on images of young, white individuals, it may perform poorly on older people or those from other ethnic backgrounds.
Variation in Appearance: The data should also cover a wide range of appearances, including different hairstyles, facial expressions, and lighting conditions. If the training data has limited variation in these aspects, the system may be biased towards detecting faces with common features.
Data Collection Methods
Sampling Bias: Examine how the training data was collected. If the data collection process favored certain locations, events, or populations, it can introduce bias. For instance, if the data is collected mainly from urban areas, the system may have difficulty detecting faces in rural or less - represented environments.
2. Performance - based Bias
Accuracy Disparities
By Demographic Group: Compare the accuracy of the face detection system across different demographic groups. Calculate metrics such as precision, recall, and F1 - score for each group. For example, if the system has a high recall for male faces but a low recall for female faces, it indicates a gender - based bias.
Under Different Conditions: Evaluate the performance of the system under various lighting conditions (e.g., bright sunlight, low - light indoor), facial expressions (e.g., smiling, frowning), and pose variations (e.g., frontal face, profile). If the system performs significantly better under certain conditions for one group compared to another, it may be biased.
False Positive and False Negative Rates
Group - specific Rates: Analyze the false positive and false negative rates for different demographic groups. A false positive occurs when the system incorrectly detects a face, while a false negative occurs when it fails to detect a face. If the false positive rate is much higher for a particular ethnic group, it can lead to unfair treatment, such as unnecessary security checks.
3. Algorithmic Bias
Feature Selection and Weighting
Inherent Bias in Features: Some features used in face detection algorithms may be more prominent in certain demographic groups. For example, if an algorithm relies heavily on a feature that is more common in one ethnic group, it may introduce bias.
Weighting of Features: The way features are weighted in the algorithm can also contribute to bias. If certain features are given more importance during the training process, it can lead to differential performance across groups.
Model Architecture
Sensitivity to Input: Different model architectures may have different sensitivities to input variations. Some architectures may be more robust to certain types of facial features or lighting conditions, which can result in bias if these variations are correlated with demographic groups.
4. Social and Ethical Implications
Impact on Individuals and Communities
Unfair Treatment: Biased face detection systems can lead to unfair treatment of individuals or entire communities. For example, in a security application, if the system is more likely to misidentify members of a particular ethnic group as a threat, it can cause discrimination and harm.
Trust and Acceptance: High levels of bias can erode public trust in face detection technology. This can have implications for the widespread adoption of these systems in various applications, such as surveillance, access control, and customer service.
5. Evaluation Metrics and Tools
Standard Metrics: Use standard evaluation metrics such as accuracy, precision, recall, and F1 - score to measure the performance of the face detection system. Additionally, calculate group - specific metrics to identify bias.
Bias - specific Metrics: There are also bias - specific metrics available, such as the Disparate Impact Ratio (DIR), which compares the performance of the system across different groups. A DIR significantly different from 1 indicates bias.
Visualization Tools: Visualization tools can be used to analyze the performance of the system across different groups. For example, creating confusion matrices or ROC curves for each demographic group can help in identifying bias patterns.
