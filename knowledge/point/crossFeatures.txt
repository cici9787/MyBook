How to utilize feature crossing to achieve more expressiveness.
https://developers.google.com/machine-learning/crash-course/categorical-data/feature-crosses?hl=zh-cn
https://zhuanlan.zhihu.com/p/618399610

通过特征交叉，将样本映射至高维空间，从而增加模型的非线性能力，提升模型的预测效果。
显式交叉：
1）內积
2）哈达玛积
3）笛卡尔积

隐式交叉：
(1)FM交叉 (2)MLP交叉
<1>FM交叉
FM 的核心在于为每个特征学习一个低维的隐向量，通过这些隐向量的内积来间接表示特征之间的交叉关系，而不是直接生成所有可能的交叉特征。
Question: 豆包
[1]比如说一个特征有200个取值，另一个特征有100个取值。正常把两个特征进行特征交叉会有200*100=2W个取值。FM如何做，可以防止取值爆炸的问题。
[2]可以帮我举出一个具体而实际的例子吗
[3]如果采用显示交叉，比如笛卡尔积，交叉后是200*100维度的特征，比如服装和北京是某个维度为1，其余19999为0.而采用FM交叉后为0.08, 为小数值。小数值和整数值作为交叉特征输入，对模型学习有什么影响。
对模型表达能力的影响
笛卡尔积交叉（整数值）：笛卡尔积交叉得到的是高维稀疏的特征向量，每个交叉特征都是独立的维度，取值为 0 或 1。这种方式能够明确地表示特征之间的组合关系，但由于维度极高且稀疏，模型需要学习大量的参数来捕捉这些特征的影响，对于罕见的特征组合，可能由于数据稀疏而无法很好地学习到其规律，限制了模型对复杂关系的表达能力。
FM 交叉（小数值）：FM 交叉通过隐向量内积得到小数值的特征表示，它能够捕捉特征之间的潜在关系，将特征组合映射到一个低维空间中，每个小数值反映了两个特征之间的关联程度。这种方式可以更好地处理数据稀疏问题，即使对于训练数据中未出现过的特征组合，也能通过隐向量的计算给出一个合理的预测值，从而增强了模型的泛化能力和对复杂关系的表达能力。
对模型训练效率的影响
笛卡尔积交叉（整数值）：高维稀疏的特征矩阵会导致计算量巨大，模型训练时间长。在梯度下降等优化算法中，大部分计算都花费在处理大量的零值上，这会浪费大量的计算资源和时间。而且，由于需要学习的参数过多，容易出现过拟合现象，尤其是在数据量有限的情况下。
FM 交叉（小数值）：低维的小数值特征表示减少了计算量和存储空间，模型训练速度更快。同时，由于参数数量相对较少，不容易出现过拟合，在有限的数据上能够更有效地学习到特征的内在规律，提高模型的训练效率和稳定性。
对模型可解释性的影响
笛卡尔积交叉（整数值）：每个交叉特征都有明确的物理意义，即表示特定的两个特征的组合是否出现，模型的可解释性相对较强。可以很直观地理解某个特征组合对模型输出的影响，例如如果 “服装 - 北京” 这个维度为 1，说明该用户购买了北京地区的服装类商品，对模型预测结果有直接的影响。
FM 交叉（小数值）：小数值的特征表示相对抽象，难以直接解释每个数值的具体含义。虽然可以通过隐向量的学习来捕捉特征之间的潜在关系，但这种关系是通过内积计算得到的，不像笛卡尔积交叉那样直观，模型的可解释性相对较弱。不过，可以通过一些方法来分析隐向量，例如观察隐向量的维度与其他特征的相关性，以尝试理解模型学习到的潜在关系。

<2>MLP交叉
(1)Deep Crossing (2)Wide&Deep (3)DCN

(3)DCN
交叉网络设计了这种层层与原始特征交叉的方式，让模型自动挖掘不同阶数的特征交叉，实现特征的自动组合和提取，减少人工特征工程的工作量.

The difference between test set and validation set.
https://zhuanlan.zhihu.com/p/29133576

双塔模型相对于单塔模型, 优缺点：
双塔优点：
1.计算效率高
2.泛化能力强
3.灵活性好
4.可解释性好
缺点：
1.模型融合难度大
2.特征交叉学习能力弱
3.训练复杂性增加

单塔
优点：
1.模型结构简单
2.特征交叉能力强
3.训练容易
缺点：
1.计算效率低
2.泛化能力若
3.灵活性差

Q:比如说我现在要训练模型，有15个点击样本85个没点击样本。大盘的点击率是0.15. 一个好的点击率预估模型产出的得分应该是什么样的，可以帮我举例具体分析一下吗？
一个好的点击率预估模型产出的得分应该在整体上与大盘点击率相匹配，同时能够在点击样本和未点击样本之间体现出合理的差异，并且能够根据样本的具体特征给出相对准确的点击概率估计。